{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study: Size of the MC Variance Depending on the Dataset Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "For this study, we apply the following formula, i.e. we omit the model and thus eliminate other error sources such as model bias and variance. When transferring this to the model feature effects (PDP and ALE), this would assume a perfect model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\widehat{\\text{Variance}}_{MC}(x_S; PDP_f, \\widehat{PDP}_f) = \\frac{1}{K}\\sum_{k=1}^K(PDP_f(x_S) - \\widehat{PDP}_f^{(k)}(x_S))^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We only perform this ablation study only for the SimpleCombined and Friedman1 groundtruth functions, since these are the only ones for which we can derive the feature effects analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from current_research_feature_effects.mappings import map_dataset_to_groundtruth\n",
    "from current_research_feature_effects.data_generating.data_generation import generate_data, Groundtruth\n",
    "from current_research_feature_effects.feature_effects import compute_theoretical_effects, compute_ales, compute_pdps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_PATH = Path(\"../experiments/mc_ablation_study\")\n",
    "os.makedirs(EXPERIMENT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/datasets.yaml\", \"r\") as file:\n",
    "    datasets_config = yaml.safe_load(file)\n",
    "\n",
    "groundtruths = [\n",
    "    map_dataset_to_groundtruth(\n",
    "        config[\"groundtruth\"],\n",
    "        [(v[\"marginal\"][\"type\"], tuple(v[\"marginal\"][\"params\"])) for v in config[\"features\"].values()],\n",
    "        np.array(config[\"correlation_matrix\"]),\n",
    "        feature_names=list(config[\"features\"].keys()),\n",
    "        name=name,\n",
    "    )\n",
    "    for name, config in datasets_config.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = np.logspace(1, 6, num=50)\n",
    "SNRS = np.array([0, 5])\n",
    "K = 50\n",
    "N_GRID_POINTS = 100\n",
    "BASE_SEED = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_mc_ablation_study(groundtruth: Groundtruth):\n",
    "    feature_names = groundtruth.feature_names\n",
    "    quantiles = np.linspace(0.0001, 0.9999, N_GRID_POINTS, endpoint=True)\n",
    "    grid_values = [groundtruth.get_theoretical_quantiles(feature, quantiles) for feature in feature_names]\n",
    "\n",
    "    ale_groundtruth_theoretical = compute_theoretical_effects(\n",
    "        groundtruth, \"ale\", feature_names, grid_values=grid_values, center_curves=True, remove_first_last=False\n",
    "    )\n",
    "    pdp_groundtruth_theoretical = compute_theoretical_effects(\n",
    "        groundtruth, \"pdp\", feature_names, grid_values=grid_values, center_curves=True, remove_first_last=False\n",
    "    )\n",
    "\n",
    "    results = {\"pdp\": defaultdict(lambda: defaultdict(dict)), \"ale\": defaultdict(lambda: defaultdict(dict))}\n",
    "\n",
    "    for snr in SNRS:\n",
    "        for n_samples in N_SAMPLES:\n",
    "            pdp_variances = defaultdict(float)\n",
    "            ale_variances = defaultdict(float)\n",
    "            for i in range(K):\n",
    "                X_mc, *_ = generate_data(\n",
    "                    groundtruth=groundtruth, n_train=int(n_samples), n_test=1, snr=snr, seed=BASE_SEED + i\n",
    "                )\n",
    "\n",
    "                pdp = compute_pdps(\n",
    "                    groundtruth,\n",
    "                    X_mc,\n",
    "                    feature_names,\n",
    "                    grid_values=grid_values,\n",
    "                    center_curves=True,\n",
    "                    remove_first_last=False,\n",
    "                )\n",
    "\n",
    "                ale = compute_ales(\n",
    "                    groundtruth,\n",
    "                    X_mc,\n",
    "                    feature_names,\n",
    "                    grid_values=grid_values,\n",
    "                    center_curves=True,\n",
    "                    remove_first_last=False,\n",
    "                )\n",
    "\n",
    "                pdp_vars = {\n",
    "                    feature: (pdp[i] - pdp_groundtruth_theoretical[i]) ** 2 for i, feature in enumerate(feature_names)\n",
    "                }\n",
    "\n",
    "                ale_vars = {\n",
    "                    feature: (ale[i] - ale_groundtruth_theoretical[i]) ** 2 for i, feature in enumerate(feature_names)\n",
    "                }\n",
    "\n",
    "                for feature in feature_names:\n",
    "                    pdp_variances[feature] += pdp_vars[feature]\n",
    "                    ale_variances[feature] += ale_vars[feature]\n",
    "\n",
    "            results[\"pdp\"][snr][n_samples] = {k: v / K for k, v in pdp_variances.items()}\n",
    "            results[\"ale\"][snr][n_samples] = {k: v / K for k, v in ale_variances.items()}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplecomb_groundtruth = groundtruths[0]\n",
    "results_simplecomb = perform_mc_ablation_study(simplecomb_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(EXPERIMENT_PATH / str(simplecomb_groundtruth), exist_ok=True)\n",
    "dump(results_simplecomb, EXPERIMENT_PATH / str(simplecomb_groundtruth) / \"ablation_results.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friedman1_groundtruth = groundtruths[1]\n",
    "results_friedman1 = perform_mc_ablation_study(friedman1_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(EXPERIMENT_PATH / str(friedman1_groundtruth), exist_ok=True)\n",
    "dump(results_friedman1, EXPERIMENT_PATH / str(friedman1_groundtruth) / \"ablation_results.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
